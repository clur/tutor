{
 "metadata": {
  "name": "Scientific Programming - Lecture 1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Scientific Programming"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Lecture 1"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Text Processing - BOW modeling & Document Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Installation and setup:\n",
      "\n",
      "For Windows users:\n",
      "http://www.psychocats.net/ubuntu/virtualbox\n",
      "(although I reccommend installing linux as your operating system, in which case: \n",
      "http://lifehacker.com/5774997/getting-started-with-linux-how-to-install-linux-on-your-computer)\n",
      "\n",
      "Note on installing NLTK for Mac users OS X 10.8 :\n",
      "\n",
      "Please follow the instructions given in this answer if you cannot import nltk:\n",
      "\n",
      "http://stackoverflow.com/questions/13395409/nltk-without-x11-on-osx-epd-64bit-python/13397480#13397480"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "print \"ntlk imported\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ntlk imported\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Code from crash course/lecture one. Note sys.argv doesn't work with ipython notebooks so I have hardcoded the file name 'sample.txt'. Here is the contents of sample text:\n"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "This is my sample text. \n",
      "There are many sample texts like it, but this one is mine.\n",
      "I like sample texts. \n",
      "If I could spend my days only writing sample texts, my life would be complete."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#filename: crashcourse-bow.py\n",
      "from __future__ import division\n",
      "from collections import Counter\n",
      "import sys\n",
      "\n",
      "#lines-list of lists of words in the text files divided into lines ('\\n')       \n",
      "lines=[l.strip().split() for l in open('sample.txt').readlines()]\n",
      "\n",
      "#words-vocabulary-all words in file and count of their occurences               \n",
      "words=Counter(open('sample.txt').read().split())\n",
      "print list(words.iterkeys())\n",
      "\n",
      "dataset=[]\n",
      "for l in lines:#for each line                                                   \n",
      "    representation=[]#store binary representation of a line in file in list     \n",
      "    for w in words:#cycle through all words in vocabulary                       \n",
      "        if w in l:\n",
      "            representation.append(1)#if vocabulary word is in line, mark a 1    \n",
      "        else:\n",
      "            representation.append(0)#if not, mark a 0                           \n",
      "    dataset.append(representation)#list of lists of binary representations      \n",
      "\n",
      "print dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['complete.', 'is', 'There', 'life', 'one', 'sample', 'texts', 'texts.', 'are', 'texts,', 'would', 'writing', 'This', 'only', 'be', 'it,', 'I', 'text.', 'but', 'like', 'this', 'many', 'could', 'days', 'mine.', 'my', 'spend', 'If']\n",
        "[[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Exercise I:\n",
      "Write a line-to-BOW script (like crashcourse-bow.py) taking only frequent words into account; e.g, words with more than m occurrences."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m=2 #number of occurences\n",
      "\n",
      "dataset=[] #reset dataset\n",
      "for l in lines:#for each line                                                   \n",
      "    representation=[]#store binary representation of a line in file in list     \n",
      "    for w in words:#cycle through all words in vocabulary                       \n",
      "        if words[w]>=m:\n",
      "            if w in l:\n",
      "                representation.append(1)#if vocabulary word is in line, mark a 1\n",
      "            else:\n",
      "                representation.append(0)#if not, mark a 0                       \n",
      "    dataset.append(representation)#list of lists of binary representations      \n",
      "\n",
      "print [(k,v) for k, v in words.items() if v >= m]#all words occuring m or more times\n",
      "print dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('is', 2), ('sample', 4), ('I', 2), ('like', 2), ('my', 3)]\n",
        "[[1, 1, 0, 0, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 0], [0, 1, 1, 0, 1], [0, 0, 0, 0, 0]]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-----"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Exercise II: Write a file-to-BOW script using import glob.\n",
      "\n",
      "Make sure you have folders set up as follows with text files in each of the folders:\n"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "ls toydata/*/*\n",
      "toydata/neg/0.txt\ttoydata/pos/0.txt\n",
      "toydata/neg/1.txt\ttoydata/pos/1.txt"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This time we are using files instead of lines in files. Each list in dataset now represents a whole file.\n",
      "import glob\n",
      "from collections import Counter as C\n",
      "\n",
      "files=glob.glob(\"toydata/*/*.txt\") #store all text filenames in files\n",
      "\n",
      "print files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['toydata/neg/0.txt', 'toydata/neg/1.txt', 'toydata/pos/0.txt', 'toydata/pos/1.txt']\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# build vocabulary                                                              \n",
      "c=C()\n",
      "for f in files: \n",
      "    c+=C(open(f).read().split()) #counter of all words in all files\n",
      "\n",
      "print c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counter({'Python': 13, 'a': 10, 'and': 9, 'is': 9, '3.x': 8, 'of': 8, 'the': 6, 'to': 5, 'where': 5, 'can': 5, 'in': 5, 'you': 5, 'using': 4, 'for': 4, 'be': 4, 'on': 4, 'that': 4, 'as': 4, '2.x': 3, 'major': 3, 'support': 3, 'more': 3, 'code': 2, 'not': 2, 'work': 2, 'people': 2, 'That': 2, 'since': 2, 'language': 2, 'range': 2, 'or': 2, 'already': 2, 'your': 2, 'use': 2, \"it's\": 2, 'mostly': 2, 'than': 2, 'xrange': 2, 'an': 2, 'have': 2, 'distributions': 2, 'supporting': 2, 'many': 2, 'limited': 1, 'they': 1, 'lack': 1, 'Twisted': 1, 'installed': 1, 'including': 1, 'still': 1, '(which': 1, 'current': 1, 'important,': 1, 'default,': 1, 'xrange()': 1, 'actually': 1, 'environment': 1, 'only': 1, 'production': 1, 'systems': 1, 'integrate': 1, 'arcane': 1, 'has': 1, 'ought': 1, 'ready.': 1, 'do': 1, 'comparatively': 1, 'handle': 1, 'gains': 1, 'far': 1, 'libraries,': 1, 'great!': 1, 'know': 1, 'Also,': 1, 'new': 1, 'end-users.': 1, 'prime': 1, 'runs': 1, 'ancient': 1, 'like': 1, 'should': 1, 'developing': 1, 'language.': 1, 'this': 1, 'control)': 1, 'said,': 1, 'noted': 1, \"isn't\": 1, 'mean': 1, 'things,': 1, 'Java': 1, 'For': 1, 'some': 1, 'library': 1, '(or': 1, 'see': 1, \"There's\": 1, 'are': 1, 'range;': 1, 'others.': 1, 'even': 1, 'what': 1, 'ported': 1, 'If': 1, 'libraries': 1, 'Linux/Unix,': 1, 'version': 1, 'various': 1, 'progress': 1, 'Twisted,': 1, 'reading': 1, 'available,': 1, 'available': 1, 'lazy': 1, 'example,': 1, 'focused': 1, 'alone': 1, 'Macs': 1, 'packages': 1, 'example:': 1, 'X,': 1, 'getting': 1, 'computers': 1, 'programming': 1, 'practical': 1, 'implementation': 1, '3.': 1, '3,': 1, 'let': 1, 'changes': 1, 'software': 1, 'point': 1, 'Windows,': 1, 'sys.maxint).': 1, 'long': 1, 'writing': 1, \"you're\": 1, 'completion.': 1, 'from': 1, 'working': 1, 'few': 1, 'deprecated': 1, 'lets': 1, 'been': 1, 'quickly': 1, 'priority': 1, 'Most': 1, 'choice.': 1, 'maintenance': 1, 'trivial.': 1, 'porting': 1, 'themselves': 1, 'servers,': 1, 'downsides,': 1, 'OS': 1, 'lot': 1, 'costs.': 1, 'exactly': 1, 'immediate': 1, 'excellent': 1, 'with': 1, 'machines.': 1, 'versions': 1, 'these': 1, 'was': 1, 'package': 1, 'effectively.': 1, 'well-written': 1, 'will': 1, 'values': 1, 'learn': 1, 'classes,': 1, 'stages': 1, 'etc.': 1, 'example': 1, 'easy,': 1, 'larger': 1, 'want': 1, 'almost': 1, '.NET': 1, 'it': 1, 'good': 1, 'something': 1, 'need': 1, 'You': 1, 'productivity': 1, 'incantations': 1, 'things': 1, 'virtual': 1, 'Mac': 1, 'better': 1, 'instead': 1, 'several': 1, 'new-style': 1, 'A': 1, 'may': 1, \"user's\": 1, 'third-party': 1, 'includes': 1, 'iterators': 1, 'most': 1, 'but': 1, 'included': 1, 'such': 1, 'lower': 1, 'older': 1, 'typically': 1, 'It': 1, '(although': 1, 'As': 1, 'definitely': 1, 'impediment': 1, 'code.': 1, 'print,': 1, 'Linux': 1, '3),': 1, 'starting': 1, 'fact': 1, '3.x,': 1})\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a function. It is created using the def keyword. It has two parameters, item and list. This function returns a '1' if the item is in the list and '0' otherwise. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def check_in(item,list):\n",
      "    if item in list:\n",
      "        return \"1\"\n",
      "    else:\n",
      "        return \"0\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note: running this code will not produce any output, functions need to be called as in the example below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#example usage\n",
      "a='banana'\n",
      "b='tomato'\n",
      "fruit=['apple','orange','banana','kiwi']\n",
      "\n",
      "print a, check_in(a,fruit)\n",
      "print b, check_in(b,fruit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Back to the excercise, we use this check_in function to create the binary representation for each file, stored in values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for f in files:\n",
      "    words=open(f).read().split()\n",
      "    values=[check_in(w,words) for w in c]\n",
      "    folder=f.split(\"/\")[-2]\n",
      "    print \" \".join([folder]+values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "neg 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
        "neg 1 0 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 1\n",
        "pos 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
        "pos 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 1 0 0\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-----"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Exercise III: Write a file-to-BOW script with TF-IDF scores."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tf-idf, term frequency-inverse document frequency\n",
      "Wikipedia:\n",
      "Suppose we have a set of English text documents and wish to determine which document is most relevant to the query \"the brown cow\". A simple way to start out is by eliminating documents that do not contain all three words \"the\", \"brown\", and \"cow\", but this still leaves many documents. To further distinguish them, we might count the number of times each term occurs in each document and sum them all together; the number of times a term occurs in a document is called its term frequency.\n",
      "\n",
      "However, because the term \"the\" is so common, this will tend to incorrectly emphasize documents which happen to use the word \"the\" more frequently, without giving enough weight to the more meaningful terms \"brown\" and \"cow\". The term \"the\" is not a good keyword to distinguish relevant and non-relevant documents and terms, unlike the less common words \"brown\" and \"cow\". Hence an inverse document frequency factor is incorporated which diminishes the weight of terms that occur very frequently in the document set and increases the weight of terms that occur rarely.\n",
      "\n",
      "(Stolen)Example:\n",
      "\n",
      "Consider a document containing 100 words wherein the word cat appears 3 times. The term frequency (i.e., tf) for cat is then (3 / 100) = 0.03. Now, assume we have 10 million documents and the word cat appears in one thousand of these. Then, the inverse document frequency (i.e., idf) is calculated as log(10,000,000 / 1,000) = 4. Thus, the Tf-idf weight is the product of these quantities: 0.03 * 4 = 0.12."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "so we want our output to look something like this:\n",
      "\n",
      "0 0 0 0 0 .43636 0 0 0 0 0 0 0 0 0 .67354 0 0 .32435 .547688 0 .00325 ....."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#add function to count inverse document frequency\n",
      "def get_idf(w,docs):\n",
      "    count=0\n",
      "    for d in docs:\n",
      "        if w in open(d).read():\n",
      "            count+=1\n",
      "    return len(docs)/count+1 #+1 because it occurs in at least 1 document from below set up\n",
      "\n",
      "import math\n",
      "\n",
      "dataset=[] #reset dataset\n",
      "\n",
      "for f in files:\n",
      "    doc=open(f).read().split()\n",
      "    representation=[]\n",
      "    for w in c:\n",
      "        if w in doc:\n",
      "            tf=doc.count(w)/len(doc) #calculate tf\n",
      "            idf=get_idf(w,files) #call get_idf function\n",
      "            representation.append(str(tf*math.log(idf))) #weight=tf*log(idf)\n",
      "        else:\n",
      "            representation.append('0')\n",
      "    dataset.append(representation)\n",
      "    \n",
      "#as before                                                                                                   \n",
      "for i in range(len(files)):\n",
      "    folder=files[i].split(\"/\")[-2]\n",
      "    print \"\\t\".join([folder]+(dataset[i]))\n",
      "    print\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "neg\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0946728183785\t0.0946728183785\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0646242522746\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0946728183785\t0\t0\t0\t0.0946728183785\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0946728183785\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0946728183785\t0\t0.0946728183785\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.189345636757\t0\t0\t0\t0.0946728183785\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0946728183785\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0646242522746\t0\t0\t0\t0\t0\t0.0946728183785\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0646242522746\t0\t0\t0\t0\t0\t0.0646242522746\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0407733635623\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
        "\n",
        "neg\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.134119826036\t0\t0\t0\t0\t0\t0.134119826036\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.134119826036\t0\t0\t0\t0\t0.134119826036\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.134119826036\t0\t0\t0.134119826036\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0915510240557\t0\t0\t0\t0\t0\t0\t0\t0\t0.134119826036\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0915510240557\t0\t0\t0\t0\t0\t0.183102048111\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.134119826036\n",
        "\n",
        "pos\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0499369222122\t0\t0\t0.073156268747\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.073156268747\t0\t0\t0.073156268747\t0.073156268747\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0385135391085\t0.0315066900255\t0\t0\t0\t0.0998738444244\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.073156268747\t0\t0.073156268747\t0\t0.073156268747\t0.073156268747\t0\t0\t0\t0\t0\t0.073156268747\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.073156268747\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.073156268747\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.073156268747\t0\t0\t0.0499369222122\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.073156268747\t0.077027078217\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0315066900255\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
        "\n",
        "pos\t0\t0.0459839403553\t0\t0\t0\t0\t0.0459839403553\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0459839403553\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0459839403553\t0.137951821066\t0\t0\t0\t0.0459839403553\t0.0459839403553\t0\t0\t0\t0\t0\t0.0459839403553\t0.0459839403553\t0\t0\t0.0459839403553\t0.0459839403553\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0919678807105\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0459839403553\t0\t0.0459839403553\t0.0459839403553\t0\t0.0459839403553\t0\t0\t0\t0\t0\t0.0242085102968\t0\t0\t0\t0\t0.0313889225334\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0459839403553\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0459839403553\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0459839403553\t0\t0\t0.0627778450667\t0\t0.0459839403553\t0\t0.0459839403553\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0.0459839403553\t0\t0\t0\t0\t0\t0\t0\t0\t0.0459839403553\t0\t0\t0\t0\t0\t0.0459839403553\t0\t0\t0\t0\t0.0198042051589\t0\t0\t0\t0\t0.0459839403553\t0\t0\t0\t0\t0\t0.0459839403553\t0.0459839403553\t0\t0\t0\t0\t0\t0\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    }
   ],
   "metadata": {}
  }
 ]
}